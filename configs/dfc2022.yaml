# lightning.pytorch==2.1.1
seed_everything: 0
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: bf16
  logger:
    class_path: TensorBoardLogger
    init_args:
      save_dir: experiments
      name: dfc2022
  callbacks:
    - class_path: TQDMProgressBar
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: epoch

  max_epochs: 100
  check_val_every_n_epoch: 1
  log_every_n_steps: 50
  enable_checkpointing: true
  default_root_dir: experiments
data:
  class_path: eosfm.datamodules.dfc2022.DFC2022DataModule
  init_args:
    batch_size: 32
    num_workers: 24
  dict_kwargs:
    root: data/dfc2022

model:
  class_path: terratorch.tasks.SemanticSegmentationTask
  init_args:
      model_factory: EncoderDecoderFactory
      model_args:
        backbone: timm_convnextv2_atto
        backbone_pretrained: True
        backbone_in_chans: 4
        decoder: UperNetDecoder
        decoder_channels: 128
        head_channel_list: [128]
        head_dropout: 0.1
        num_classes: 16
      loss: dice
      ignore_index: -1
      freeze_backbone: false
      freeze_decoder: false 
      plot_on_val: false
    
optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 1.e-4
    weight_decay: 0.1
# lr_scheduler:
#   class_path: ReduceLROnPlateau
#   init_args:
#     monitor: val/loss

